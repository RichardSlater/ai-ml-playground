{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Post-processing VQGAN Images\n",
    "\n",
    "## Check for missing images in the sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "working_dir = \"../content\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: Pillow in c:\\users\\mcp\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (9.0.1)\n"
     ]
    }
   ],
   "source": [
    "!python3 -m pip install --upgrade Pillow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enumerating frames:\n",
      "All frames appear to be in place.\n"
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "\n",
    "print(\"Enumerating frames:\")\n",
    "steps_dir = join(working_dir, \"steps\")\n",
    "files = [f for f in listdir(steps_dir) if isfile(join(steps_dir, f))]\n",
    "dirty = False\n",
    "\n",
    "for i in range(1, len(files) + 1):\n",
    "    frame = join(steps_dir, f\"{i:04d}.png\")\n",
    "    if (not isfile(frame)):\n",
    "        print(f\"  {frame} missing\")\n",
    "        dirty = True\n",
    "        continue\n",
    "    original = Image.open(frame)\n",
    "    width, height = original.size\n",
    "    if width != 368:\n",
    "        print(f\"  {frame} width is {width} rather than 368px\")\n",
    "        dirty = True\n",
    "    if height != 640:\n",
    "        print(f\"  {frame} height is {height} rather than 368px\")\n",
    "        dirty = True\n",
    "\n",
    "if dirty:\n",
    "    print(\"At least one frame in the sequence is missing or incorrect!\")\n",
    "else:\n",
    "    print(f\"All frames appear to be in place.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cropping the image\n",
    "\n",
    "Due to the way the height and width are cacluated in Katherine Crowson's python code you can lose 8 pixels from 360px, we can compensate for this by rendering the images at 368px however this means we have 4px on either side that is vestigial for a 9:16 resolution. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "from pathlib import Path\n",
    "\n",
    "steps_dir = join(working_dir, \"steps\")\n",
    "cropped_steps_dir = join(working_dir, \"cropped_steps\")\n",
    "Path(cropped_steps_dir).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "for i in range(1, len(files) + 1):\n",
    "    frame_filename = f\"{i:04d}.png\"\n",
    "    frame = join(steps_dir, frame_filename)\n",
    "    target_frame_file = join(cropped_steps_dir, frame_filename)\n",
    "\n",
    "    if os.path.isfile(target_frame_file):\n",
    "        continue\n",
    "\n",
    "    original = Image.open(frame)\n",
    "    width, height = original.size\n",
    "\n",
    "    targetWidth, targetHeight = 360, 640\n",
    "    \n",
    "    left = (width - targetWidth) / 2\n",
    "    top = (height - targetHeight) / 2\n",
    "    right = width - ((width - targetWidth) / 2)\n",
    "    bottom = height - ((height - targetHeight) / 2)\n",
    "\n",
    "    cropped_frame = original.crop((left, top, right, bottom))\n",
    "\n",
    "    cropped_frame.save(target_frame_file)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Super Sampling with SRCNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "fatal: destination path '../content\\ais\\SRCNN' already exists and is not an empty directory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numpy in c:\\users\\mcp\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (1.22.2)\n",
      "Requirement already satisfied: Pillow in c:\\users\\mcp\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (9.0.1)\n",
      "Looking in links: https://download.pytorch.org/whl/nightly/cu113/torch_nightly.html\n",
      "Requirement already satisfied: torch in c:\\users\\mcp\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (1.12.0.dev20220211+cu113)\n",
      "Requirement already satisfied: torchvision in c:\\users\\mcp\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (0.13.0.dev20220212+cu113)\n",
      "Requirement already satisfied: torchaudio in c:\\users\\mcp\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (0.11.0.dev20220212+cu113)\n",
      "Requirement already satisfied: typing-extensions in c:\\users\\mcp\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from torch) (4.0.1)\n",
      "Requirement already satisfied: numpy in c:\\users\\mcp\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from torchvision) (1.22.2)\n",
      "Requirement already satisfied: requests in c:\\users\\mcp\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from torchvision) (2.27.1)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in c:\\users\\mcp\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from torchvision) (9.0.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\mcp\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from requests->torchvision) (3.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\mcp\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from requests->torchvision) (2021.10.8)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\mcp\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from requests->torchvision) (1.26.8)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in c:\\users\\mcp\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from requests->torchvision) (2.0.12)\n"
     ]
    }
   ],
   "source": [
    "ais_dir = join(working_dir, \"ais\")\n",
    "srcnn_dir = join(ais_dir, \"SRCNN\")\n",
    "\n",
    "!git clone https://github.com/Mirwaisse/SRCNN.git $srcnn_dir\n",
    "\n",
    "!python3 -m pip install --upgrade numpy \n",
    "!python3 -m pip install --upgrade Pillow \n",
    "!python3 -m pip install --pre torch torchvision torchaudio -f https://download.pytorch.org/whl/nightly/cu113/torch_nightly.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib.request\n",
    "\n",
    "models_dir = join(working_dir, \"models\")\n",
    "Path(models_dir).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "for model in [\"2x\", \"3x\", \"4x\"]:\n",
    "    urllib.request.urlretrieve(f\"https://raw.githubusercontent.com/justinjohn0306/SRCNN/master/models/model_{model}.pth\", join(models_dir, f\"model_{model}.pth\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Upscaling frame 555 (0555.png)\n",
      "Upscaling frame 556 (0556.png)\n",
      "Upscaling frame 557 (0557.png)\n",
      "Upscaling frame 558 (0558.png)\n",
      "Upscaling frame 559 (0559.png)\n",
      "Upscaling frame 560 (0560.png)\n",
      "Upscaling frame 561 (0561.png)\n",
      "Upscaling frame 562 (0562.png)\n",
      "Upscaling frame 563 (0563.png)\n",
      "Upscaling frame 564 (0564.png)\n",
      "Upscaling frame 565 (0565.png)\n",
      "Upscaling frame 566 (0566.png)\n",
      "Upscaling frame 567 (0567.png)\n",
      "Upscaling frame 568 (0568.png)\n",
      "Upscaling frame 569 (0569.png)\n",
      "Upscaling frame 570 (0570.png)\n",
      "Upscaling frame 571 (0571.png)\n",
      "Upscaling frame 572 (0572.png)\n",
      "Upscaling frame 573 (0573.png)\n",
      "Upscaling frame 574 (0574.png)\n",
      "Upscaling frame 575 (0575.png)\n",
      "Upscaling frame 576 (0576.png)\n",
      "Upscaling frame 577 (0577.png)\n",
      "Upscaling frame 578 (0578.png)\n",
      "Upscaling frame 579 (0579.png)\n",
      "Upscaling frame 580 (0580.png)\n",
      "Upscaling frame 581 (0581.png)\n",
      "Upscaling frame 582 (0582.png)\n",
      "Upscaling frame 583 (0583.png)\n",
      "Upscaling frame 584 (0584.png)\n",
      "Upscaling frame 585 (0585.png)\n",
      "Upscaling frame 586 (0586.png)\n",
      "Upscaling frame 587 (0587.png)\n",
      "Upscaling frame 588 (0588.png)\n",
      "Upscaling frame 589 (0589.png)\n",
      "Upscaling frame 590 (0590.png)\n",
      "Upscaling frame 591 (0591.png)\n",
      "Upscaling frame 592 (0592.png)\n",
      "Upscaling frame 593 (0593.png)\n",
      "Upscaling frame 594 (0594.png)\n",
      "Upscaling frame 595 (0595.png)\n",
      "Upscaling frame 596 (0596.png)\n",
      "Upscaling frame 597 (0597.png)\n",
      "Upscaling frame 598 (0598.png)\n",
      "Upscaling frame 599 (0599.png)\n",
      "Upscaling frame 600 (0600.png)\n"
     ]
    }
   ],
   "source": [
    "import subprocess\n",
    "import shutil\n",
    "from os.path import isfile, join\n",
    "from pathlib import Path\n",
    "\n",
    "# Set zoomed = True if this cell is run\n",
    "zoomed = True\n",
    "\n",
    "resolution = \"3x\" #@param [\"2x\", \"3x\", \"4x\"] {type:\"string\"}\n",
    "zoom_factor = resolution.rstrip(\"x\")\n",
    "\n",
    "cropped_steps_dir = join(working_dir, \"cropped_steps\")\n",
    "zoomed_steps_dir = join(working_dir, \"zoomed_steps\")\n",
    "Path(zoomed_steps_dir).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "for i in range(1, len(files) + 1):\n",
    "    frame_filename = f\"{i:04d}.png\"\n",
    "    target_frame_file = join(zoomed_steps_dir, frame_filename)\n",
    "\n",
    "    if isfile(target_frame_file):\n",
    "        continue\n",
    "\n",
    "    cmd = [\n",
    "        'python3',\n",
    "        '../../content/ais/SRCNN/run.py',\n",
    "        '--zoom_factor',\n",
    "        zoom_factor,  # Note if you increase this, you also need to change the model.\n",
    "        '--model',\n",
    "        f\"../../content/models/model_{resolution}.pth\",  # 2x, 3x and 4x are available from the repo above\n",
    "        '--image',\n",
    "        frame_filename,\n",
    "        '--cuda'\n",
    "    ]\n",
    "    print(f'Upscaling frame {i} ({frame_filename})')\n",
    "\n",
    "    process = subprocess.Popen(cmd, cwd=cropped_steps_dir)\n",
    "    stdout, stderr = process.communicate()\n",
    "    if process.returncode != 0:\n",
    "        print(stdout)\n",
    "        print(stderr)\n",
    "        raise RuntimeError(stderr)\n",
    "\n",
    "    shutil.move(join(cropped_steps_dir, f\"zoomed_{frame_filename}\"), target_frame_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python3 -m pip install ffmpeg-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(None, None)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import ffmpeg\n",
    "import os\n",
    "from os.path import isfile, join\n",
    "\n",
    "zoomed_steps_dir = os.path.abspath(join(working_dir, \"zoomed_steps\"))\n",
    "video_file = os.path.abspath(join(working_dir, \"video.mp4\"))\n",
    "\n",
    "if isfile(video_file):\n",
    "    os.remove(video_file)\n",
    "\n",
    "(\n",
    "ffmpeg\n",
    "    .input(f'{zoomed_steps_dir}\\%04d.png', pattern_type='sequence', s='1080x1920', framerate=12)\n",
    "    .output(video_file, preset='fast')\n",
    "    .run()\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "76e39a95be4d5898a3570c447c27edaa62298e3a74d4da47c7cca3211a7c59ee"
  },
  "kernelspec": {
   "display_name": "Python 3.9.10 64-bit (windows store)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
