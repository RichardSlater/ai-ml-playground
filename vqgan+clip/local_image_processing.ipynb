{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Post-processing VQGAN Images\n",
    "\n",
    "## Check for missing images in the sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "working_dir = \"../content\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python3 -m pip install --upgrade Pillow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "\n",
    "print(\"Enumerating frames:\")\n",
    "steps_dir = join(working_dir, \"steps\")\n",
    "files = [f for f in listdir(steps_dir) if isfile(join(steps_dir, f))]\n",
    "dirty = False\n",
    "\n",
    "for i in range(1, len(files) + 1):\n",
    "    frame = join(steps_dir, f\"{i:04d}.png\")\n",
    "    if (not isfile(frame)):\n",
    "        print(f\"  {frame} missing\")\n",
    "        dirty = True\n",
    "        continue\n",
    "    original = Image.open(frame)\n",
    "    width, height = original.size\n",
    "    if width != 368:\n",
    "        print(f\"  {frame} width is {width} rather than 368px\")\n",
    "        dirty = True\n",
    "    if height != 640:\n",
    "        print(f\"  {frame} height is {height} rather than 368px\")\n",
    "        dirty = True\n",
    "\n",
    "if dirty:\n",
    "    print(\"At least one frame in the sequence is missing or incorrect!\")\n",
    "else:\n",
    "    print(f\"All frames appear to be in place.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cropping the image\n",
    "\n",
    "Due to the way the height and width are cacluated in Katherine Crowson's python code you can lose 8 pixels from 360px, we can compensate for this by rendering the images at 368px however this means we have 4px on either side that is vestigial for a 9:16 resolution. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "from pathlib import Path\n",
    "\n",
    "steps_dir = join(working_dir, \"steps\")\n",
    "cropped_steps_dir = join(working_dir, \"cropped_steps\")\n",
    "Path(cropped_steps_dir).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "for i in range(1, len(files) + 1):\n",
    "    frame_filename = f\"{i:04d}.png\"\n",
    "    frame = join(steps_dir, frame_filename)\n",
    "    target_frame_file = join(cropped_steps_dir, frame_filename)\n",
    "\n",
    "    if os.path.isfile(target_frame_file):\n",
    "        continue\n",
    "\n",
    "    original = Image.open(frame)\n",
    "    width, height = original.size\n",
    "\n",
    "    targetWidth, targetHeight = 360, 640\n",
    "    \n",
    "    left = (width - targetWidth) / 2\n",
    "    top = (height - targetHeight) / 2\n",
    "    right = width - ((width - targetWidth) / 2)\n",
    "    bottom = height - ((height - targetHeight) / 2)\n",
    "\n",
    "    cropped_frame = original.crop((left, top, right, bottom))\n",
    "\n",
    "    cropped_frame.save(target_frame_file)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Super Sampling with SRCNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ais_dir = join(working_dir, \"ais\")\n",
    "srcnn_dir = join(ais_dir, \"SRCNN\")\n",
    "\n",
    "!git clone https://github.com/Mirwaisse/SRCNN.git $srcnn_dir\n",
    "\n",
    "!python3 -m pip install --upgrade numpy \n",
    "!python3 -m pip install --upgrade Pillow \n",
    "!python3 -m pip install --pre torch torchvision torchaudio -f https://download.pytorch.org/whl/nightly/cu113/torch_nightly.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib.request\n",
    "\n",
    "models_dir = join(working_dir, \"models\")\n",
    "Path(models_dir).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "for model in [\"2x\", \"3x\", \"4x\"]:\n",
    "    urllib.request.urlretrieve(f\"https://raw.githubusercontent.com/justinjohn0306/SRCNN/master/models/model_{model}.pth\", join(models_dir, f\"model_{model}.pth\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "import shutil\n",
    "from os.path import isfile, join\n",
    "from pathlib import Path\n",
    "\n",
    "# Set zoomed = True if this cell is run\n",
    "zoomed = True\n",
    "\n",
    "resolution = \"3x\" #@param [\"2x\", \"3x\", \"4x\"] {type:\"string\"}\n",
    "zoom_factor = resolution.rstrip(\"x\")\n",
    "\n",
    "cropped_steps_dir = join(working_dir, \"cropped_steps\")\n",
    "zoomed_steps_dir = join(working_dir, \"zoomed_steps\")\n",
    "Path(zoomed_steps_dir).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "for i in range(1, len(files) + 1):\n",
    "    frame_filename = f\"{i:04d}.png\"\n",
    "    target_frame_file = join(zoomed_steps_dir, frame_filename)\n",
    "\n",
    "    if isfile(target_frame_file):\n",
    "        continue\n",
    "\n",
    "    cmd = [\n",
    "        'python3',\n",
    "        '../../content/ais/SRCNN/run.py',\n",
    "        '--zoom_factor',\n",
    "        zoom_factor,  # Note if you increase this, you also need to change the model.\n",
    "        '--model',\n",
    "        f\"../../content/models/model_{resolution}.pth\",  # 2x, 3x and 4x are available from the repo above\n",
    "        '--image',\n",
    "        frame_filename,\n",
    "        '--cuda'\n",
    "    ]\n",
    "    print(f'Upscaling frame {i} ({frame_filename})')\n",
    "\n",
    "    process = subprocess.Popen(cmd, cwd=cropped_steps_dir)\n",
    "    stdout, stderr = process.communicate()\n",
    "    if process.returncode != 0:\n",
    "        print(stdout)\n",
    "        print(stderr)\n",
    "        raise RuntimeError(stderr)\n",
    "\n",
    "    shutil.move(join(cropped_steps_dir, f\"zoomed_{frame_filename}\"), target_frame_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python3 -m pip install ffmpeg-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ffmpeg\n",
    "import os\n",
    "from os.path import isfile, join\n",
    "\n",
    "zoomed_steps_dir = os.path.abspath(join(working_dir, \"zoomed_steps\"))\n",
    "video_file = os.path.abspath(join(working_dir, \"video.mp4\"))\n",
    "\n",
    "if isfile(video_file):\n",
    "    os.remove(video_file)\n",
    "\n",
    "(\n",
    "ffmpeg\n",
    "    .input(f'{zoomed_steps_dir}\\%04d.png', pattern_type='sequence', s='1080x1920', framerate=12)\n",
    "    .output(video_file, preset='fast')\n",
    "    .run()\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "76e39a95be4d5898a3570c447c27edaa62298e3a74d4da47c7cca3211a7c59ee"
  },
  "kernelspec": {
   "display_name": "Python 3.9.10 64-bit (windows store)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
